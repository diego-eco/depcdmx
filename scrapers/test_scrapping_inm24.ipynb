{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module to scrape Inmuebles 24\n",
    "and stores data in local storage as CSV.\n",
    "\n",
    "Fetched Fields:\n",
    "name, description, location, link, price, operation, rooms, bathrooms, construction (m2), terrain (m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\\2023-03-28\\inmuebles24-ciudad-de-mexico-venta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vars\n",
    "_root = 'https://www.inmuebles24.com/'\n",
    "_state = 'ciudad-de-mexico'\n",
    "_operation = 'venta'\n",
    "_base_url = _root + \"inmuebles-en-\" + _operation + \"-en-\" + _state + \"-pagina-{}.html\"\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.82 Safari/537.36'\n",
    "ddir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(depts):\n",
    "    \"\"\" Append page data\n",
    "\n",
    "        Params:\n",
    "        -----\n",
    "        depts : pd.Dataframe()\n",
    "            Dataframe of Departments\n",
    "    \"\"\"\n",
    "    # Read Existant file to append\n",
    "    _fname = ddir + \"{}\\inmuebles24\" + \"-\" + _state + \"-\" + _operation + \".csv\"\n",
    "    _fname = _fname.format(dt.date.today().isoformat())\n",
    "    try:\n",
    "        df = pd.read_csv(_fname, delimiter=',')\n",
    "    except:\n",
    "        print('New file, creating folder..')\n",
    "        try:\n",
    "            os.mkdir(ddir + '{}'.format(dt.date.today().isoformat()))\n",
    "            print('Created folder!')\n",
    "        except:\n",
    "            print('Folder exists already!')\n",
    "        df = pd.DataFrame()\n",
    "    # Append data\n",
    "    print(depts.head(1).to_dict())\n",
    "    try:\n",
    "        if df.empty:\n",
    "            depts.set_index(['name', 'location']).to_csv(_fname, sep=',')\n",
    "            print('Correctly saved file: {}'.format(_fname))\n",
    "        else:\n",
    "            df = pd.concat([df, depts])\n",
    "            df.set_index(['name', 'location']).to_csv(_fname, sep=',')\n",
    "            print('Correctly saved file: {}'.format(_fname))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Could not save file: {}'.format(_fname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(content):\n",
    "    \"\"\" Scrape all listings per page \"\"\"\n",
    "    columns = ['name',\n",
    "               'description',\n",
    "               'location',\n",
    "               'link',\n",
    "               'price',\n",
    "               'operation',\n",
    "               'rooms',\n",
    "               'bathrooms',\n",
    "               'construction (m2)',\n",
    "               'terrain (m2)']\n",
    "\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    # Generate soup\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    # Get Characteristics\n",
    "    for d in soup.find_all(class_=\"posting-card\"):\n",
    "        temp_dict = {}\n",
    "        try:\n",
    "            temp_dict['name'] = d.find(class_=\"posting-title\").text.strip()\n",
    "            temp_dict['description'] = d.find(class_=\"posting-description\").text.strip()\n",
    "            temp_dict['location'] = ' '.join([j.strip() for j in d.find(class_=\"posting-location\").text.strip().split('\\n')])\n",
    "            temp_dict['link'] = d.find(class_=\"posting-title\").find('a').get('href')\n",
    "            temp_dict['price'] = d.find(class_=\"first-price\").text.strip()\n",
    "            temp_dict['operation'] = _operation\n",
    "            for li in d.find(class_=\"main-features\").findAll('li'):\n",
    "                li = li.text.lower()\n",
    "                if 'recámara' in li:\n",
    "                    temp_dict['rooms'] = statistics.mean([int(s) for s in li.split() if s.isdigit()])\n",
    "                elif 'baño' in li:\n",
    "                    temp_dict['bathrooms'] = statistics.mean([int(s) for s in li.split() if s.isdigit()])\n",
    "                elif 'construido' in li:\n",
    "                    temp_dict['construction (m2)'] = statistics.mean([int(s) for s in li.split() if s.isdigit()])\n",
    "                elif 'terreno' in li:\n",
    "                    temp_dict['terrain (m2)'] = statistics.mean([int(s) for s in li.split() if s.isdigit()])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        data = data.append(temp_dict, ignore_index=True)\n",
    "    print('Found {} depts'.format(len(data['name'])))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paginate():\n",
    "    \"\"\" Loop over pages to retrieve all info available\n",
    "\n",
    "        Returns:\n",
    "        -----\n",
    "        pg_nums : int\n",
    "            Number of pages scraped\n",
    "    \"\"\"\n",
    "    pg_nums = 1\n",
    "    while True:\n",
    "        try:\n",
    "            print(_base_url.format(pg_nums))\n",
    "            r = requests.get(_base_url.format(pg_nums),\n",
    "                             headers={'user-agent': user_agent})\n",
    "            if r.status_code != 200:\n",
    "                raise Exception(\"Wrong Response\")\n",
    "            depts = scrape(r.content)\n",
    "            if depts.empty:\n",
    "                raise Exception(\"No more departments\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Finishing to retrieve info.')\n",
    "            break\n",
    "        # Store values\n",
    "        save(depts)\n",
    "        pg_nums += 1\n",
    "    return pg_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.inmuebles24.com/inmuebles-en-venta-en-ciudad-de-mexico-pagina-1.html\n",
      "Found 0 depts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>price</th>\n",
       "      <th>operation</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>construction (m2)</th>\n",
       "      <th>terrain (m2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, description, location, link, price, operation, rooms, bathrooms, construction (m2), terrain (m2)]\n",
       "Index: []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_nums = 1\n",
    "print(_base_url.format(pg_nums))\n",
    "r = requests.get(_base_url.format(pg_nums),\n",
    "                             headers={'user-agent': user_agent})\n",
    "depts = scrape(r.content)\n",
    "depts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'httpx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9416/258835583.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_base_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpg_nums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'user-agent'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'httpx'"
     ]
    }
   ],
   "source": [
    "\n",
    "requests.get(_base_url.format(pg_nums), headers={'user-agent': user_agent})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af7ce5840f66976e743f9e75faeb392db5646844c393262a9b8f21752ae9f7e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
